{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep_Learning_Models.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"K37OeDTJ3pxa"},"source":["# CONVOLUTIONAL NEURONAL NETWORKS AND ARTIFICIAL NEURONAL NETWORKS FOR FLOW PATTERNS CLASSIFICATION"]},{"cell_type":"code","metadata":{"id":"1Uls3o-Hr9-h"},"source":["!nvidia-smi ### GPU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eSb0NpergLhP"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g72lntaxgL0s"},"source":["## Database address, enter your own Drive address.\n","PATH = './BDOShohamIML.csv' \n","path = \"./\" #Path for metric images"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hwWzJ3H7s1Vx"},"source":["## Libraries"]},{"cell_type":"code","metadata":{"id":"M0gRVrcYsBs8"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","import time as tm\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YLPzaDX8s-7G"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"uxvcA4gesIim"},"source":["## Loading Data\n","\n","# Velocity, Viscosity, Density, Surface Tension, Angle and Diameter\n","dataset = pd.DataFrame(pd.read_csv(PATH), columns=['Vsl', 'Vsg', 'VisL', 'VisG', 'DenL', 'DenG', 'ST', 'Ang', 'ID', 'Flow Pattern']) \n","\n","# Summarize the Dataset \n","print(\"shape of initial data =\",dataset.shape) \n","# Class Distribution \n","print(dataset.groupby('Flow Pattern').size()) \n","# Leaving only the best training variables\n","dataset = dataset.drop(['VisG', 'VisL','DenG', 'ST', 'DenL'], axis=1) #Delete this variables\n","print(\"shape of selected data =\",dataset.shape) \n","\n","print(dataset.head()) \n","\n","# Split-out validation dataset \n","array = dataset.values \n","X = array[:,0:4] #Data or features \n","Y = array[:,4]   #Label or classes \n","validation_size = 0.20\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=validation_size, random_state=510) \n","\n","## Data preparation for neural networks\n","X_train_ = X_train\n","X_test_ = X_test\n","\n","#Renaming labels for y_train\n","Yt = y_train.copy()\n","for i in range(len(Yt)):\n","    if Yt[i] == 'A':\n","        Yt[i] = 0\n","    elif Yt[i] == 'B':\n","        Yt[i] = 1\n","    elif Yt[i] == 'DB':\n","        Yt[i] = 2\n","    elif Yt[i] == 'I':\n","        Yt[i] = 3\n","    elif Yt[i] == 'SS':\n","        Yt[i] = 4\n","    elif Yt[i] == 'SW':\n","        Yt[i] = 5\n","    else:\n","        print(\"Dimesion error\")\n","\n","Yt = np.array(np.eye(6)[np.array(Yt, dtype=int)], dtype=np.float32) #For the Softmax activation function\n","\n","#Renaming labels for y_train\n","Yv = y_test.copy()\n","for i in range(len(Yv)):\n","    if Yv[i] == 'A':\n","        Yv[i] = 0\n","    elif Yv[i] == 'B':\n","        Yv[i] = 1\n","    elif Yv[i] == 'DB':\n","        Yv[i] = 2\n","    elif Yv[i] == 'I':\n","        Yv[i] = 3\n","    elif Yv[i] == 'SS':\n","        Yv[i] = 4\n","    elif Yv[i] == 'SW':\n","        Yv[i] = 5\n","    else:\n","        print(\"Dimesion error\")\n","\n","Yv = np.array(np.eye(6)[np.array(Yv, dtype=int)], dtype=np.float32) #For the Softmax activation function\n","\n","X_train = np.expand_dims(X_train,axis=2)\n","X_test  = np.expand_dims(X_test,axis=2)\n","X_train = np.array(X_train, dtype=np.float64)\n","X_test  = np.array(X_test, dtype=np.float64)\n","y_train = Yt\n","y_test = Yv\n","print(\"\\ntrain data shape =\",X_train.shape) \n","print(\"train labels shape =\",y_train.shape) \n","print(\"test data shape =\",X_test.shape) \n","print(\"test labels shape =\",y_test.shape) \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jGxKaezGUFIf"},"source":["## CONVOLUTIONAL NEURAL NETWORKS"]},{"cell_type":"code","metadata":{"id":"xCzBOggDUBku"},"source":["def modelCNN():\n","  ip = tf.keras.layers.Input(shape=[X_train_.shape[1],1])\n","  layers = tf.keras.layers.Conv1D(filters=32, kernel_size=(1), activation='relu')(ip) \n","  layers = tf.keras.layers.Conv1D(filters=32, kernel_size=(1), activation='relu')(layers)\n","  layers = tf.keras.layers.MaxPooling1D(1)(layers)\n","  layers = tf.keras.layers.Conv1D(filters=32, kernel_size=(1), activation='relu')(layers) \n","  layers = tf.keras.layers.Flatten()(layers)\n","  layers = tf.keras.layers.Dense(512, activation=\"selu\")(layers) \n","  layers = tf.keras.layers.Dense(256, activation=\"selu\")(layers)\n","  layers = tf.keras.layers.Dense(128, activation=\"selu\")(layers)\n","  layers = tf.keras.layers.Dense(64, activation=\"selu\")(layers) \n","  x = tf.keras.layers.Dense(6, activation=\"softmax\", name=\"output_1\")(layers) \n","  model = tf.keras.Model(inputs=ip, outputs=x) \n","  optimizer = tf.keras.optimizers.RMSprop() \n","  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","  return model \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JosK_4BDUBrX"},"source":["modelCNN = modelCNN() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxhhiKJbUCRM"},"source":["# BEST CNN MODEL\n","epochs = 700\n","batch_size=64\n","\n","lossTRAIN,accuracyTRAIN = modelCNN.evaluate(X_train, y_train, verbose=None)\n","lossTEST,accuracyTEST   = modelCNN.evaluate(X_test, y_test, verbose=None)\n","start_time = tm.time()\n","history=modelCNN.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test),verbose=2)\n","TIME = tm.time() - start_time\n","print(\"\\nTime: {0:.4f} [seconds]\".format(TIME))\n","\n","with plt.style.context('seaborn-white'):\n","    plt.figure(figsize=(10, 10))\n","    #Plot training & validation accuracy values\n","    plt.plot(np.concatenate([np.array([accuracyTRAIN]),np.array(history.history['accuracy'])],axis=0))\n","    plt.plot(np.concatenate([np.array([accuracyTEST]), np.array(history.history['val_accuracy'])],axis=0))\n","    plt.title('Accuracy Vs Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Test'], loc='upper left')\n","    plt.grid('on')\n","    #plt.savefig(\"./path/CNN_acc.pdf\", format='pdf')\n","    plt.show()\n","    \n","    plt.figure(figsize=(10, 10))\n","    #Plot training & validation loss values\n","    plt.plot(np.concatenate([np.array([lossTRAIN]),np.array(history.history['loss'])],axis=0))\n","    plt.plot(np.concatenate([np.array([lossTEST]), np.array(history.history['val_loss'])],axis=0))\n","    plt.title('Loss Vs Epoch')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Test'], loc='upper left')\n","    plt.grid('on')\n","    #plt.savefig(\"./path/CNN_loss.pdf\", format='pdf')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oxZoisO0sIvC"},"source":["## ARTIFICIAL NEURAL NETWORKS"]},{"cell_type":"code","metadata":{"id":"6Cpv2alkXLag"},"source":["def modelANN():\n","  ip = tf.keras.layers.Input(shape=[X_train_.shape[1]])\n","  layers = tf.keras.layers.Dense(512, activation=\"selu\")(ip) \n","  layers = tf.keras.layers.Dense(256, activation=\"selu\")(layers)\n","  layers = tf.keras.layers.Dense(128, activation=\"selu\")(layers)\n","  layers = tf.keras.layers.Dense(64, activation=\"selu\")(layers) \n","  x = tf.keras.layers.Dense(6, activation=\"softmax\", name=\"output_1\")(layers) \n","  model = tf.keras.Model(inputs=ip, outputs=x) \n","  optimizer = tf.keras.optimizers.RMSprop() \n","  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","  return model \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAeOLb003DPB"},"source":["modelANN = modelANN() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UlWhgyVFsMEn"},"source":["# BEST ANN MODEL\n","epochs = 1200\n","batch_size=64\n","\n","lossTRAIN,accuracyTRAIN = modelANN.evaluate(X_train, y_train, verbose=None)\n","lossTEST,accuracyTEST   = modelANN.evaluate(X_test, y_test, verbose=None)\n","start_time = tm.time()\n","history=modelANN.fit(X_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_test, y_test),verbose=2)\n","TIME = tm.time() - start_time\n","print(\"\\nTime: {0:.4f} [seconds]\".format(TIME))\n","\n","with plt.style.context('seaborn-white'):\n","    plt.figure(figsize=(10, 10))\n","    #Plot training & validation accuracy values\n","    plt.plot(np.concatenate([np.array([accuracyTRAIN]),np.array(history.history['accuracy'])],axis=0))\n","    plt.plot(np.concatenate([np.array([accuracyTEST]), np.array(history.history['val_accuracy'])],axis=0))\n","    plt.title('Accuracy Vs Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Test'], loc='upper left')\n","    plt.grid('on')\n","    #plt.savefig(\"./path/ANN_acc.pdf\", format='pdf')\n","    plt.show()\n","    \n","    plt.figure(figsize=(10, 10))\n","    #Plot training & validation loss values\n","    plt.plot(np.concatenate([np.array([lossTRAIN]),np.array(history.history['loss'])],axis=0))\n","    plt.plot(np.concatenate([np.array([lossTEST]), np.array(history.history['val_loss'])],axis=0))\n","    plt.title('Loss Vs Epoch')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Test'], loc='upper left')\n","    plt.grid('on')\n","    #plt.savefig(\"./path/ANN_loss.pdf\", format='pdf')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tqT-AlrDXbNn"},"source":[""],"execution_count":null,"outputs":[]}]}